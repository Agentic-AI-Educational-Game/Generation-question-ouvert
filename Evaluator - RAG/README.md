
# ğŸ§  Ã‰valuateur de RÃ©ponses d'Ã‰tudiants avec RAG

Une application **Flask** simple utilisant **LangChain**, **Groq LLM**, le stockage vectoriel **FAISS** et les embeddings **SentenceTransformer** pour :
- GÃ©nÃ©rer des rÃ©ponses Ã  partir de textes fournis via la GÃ©nÃ©ration AugmentÃ©e par RÃ©cupÃ©ration (RAG)
- Ã‰valuer les rÃ©ponses d'Ã©tudiants avec des retours dÃ©taillÃ©s et une notation

---

## ğŸ–¼ï¸ Stack Technologique

| Technologie | Description |
|-----------|-------------|
| **Python** | Langage principal de la logique backend |
| **Flask** | Framework web lÃ©ger pour construire des APIs |
| **LangChain** | Framework pour crÃ©er des applications basÃ©es sur des LLMs |
| **Groq LLM** | Fournisseur de LLM Ã  infÃ©rence rapide (utilise DeepSeek-LLaMA) |
| **FAISS** | Moteur de recherche vectorielle pour une rÃ©cupÃ©ration rapide |
| **SentenceTransformer** | GÃ©nÃ¨re des embeddings pour le texte |

---

## ğŸš€ Fonctionnement

### Ã‰tapes :

1. **ğŸ“‚ Chargement des donnÃ©es** :  
   Charge un fichier `.jsonl` contenant les documents texte.

2. **ğŸ” CrÃ©ation des embeddings** :  
   Utilise `SentenceTransformer` (`all-MiniLM-L6-v2`) pour vectoriser les textes.

3. **ğŸ“š Construction du stockage FAISS** :  
   Stocke ces vecteurs dans un index FAISS pour une recherche sÃ©mantique rapide.

4. **ğŸ§  Configuration de la chaÃ®ne RAG** :  
   Utilise `RetrievalQA` de **LangChain** avec le modÃ¨le **LLaMA de Groq** pour gÃ©nÃ©rer des rÃ©ponses basÃ©es sur des questions.

5. **ğŸ“ˆ Ã‰valuation des rÃ©ponses** :  
   Prend une rÃ©ponse d'Ã©tudiant et :
   - Trouve la rÃ©ponse correcte via RAG
   - Utilise Groq pour Ã©valuer la rÃ©ponse
   - Retourne une correction, une analyse des erreurs et une note sur 10

---

## ğŸ“® Point de Terminaison API

### `POST /evaluate_answer`

**RequÃªte JSON :**
```json
{
  "text": "The water cycle has three main stages...",
  "question": "What are the stages of the water cycle?",
  "student_answer": "Evaporation and precipitation only"
}
```

**RÃ©ponse JSON :**

```json
{
  "correction": "The student forgot to mention condensation.",
  "error": "Missing stage: condensation.",
  "evaluation": "6/10"
}
```

---

## âš™ï¸ Configuration

CrÃ©ez un fichier `.env` :

```bash
GROQ_API_KEY=votre_clÃ©_api_groq_ici
```

Installez les dÃ©pendances :

```bash
pip install -r requirements.txt
```

Lancez le serveur :

```bash
python app.py
```

---

## ğŸ“ Structure des Fichiers

```
.
â”œâ”€â”€ app.py                # Application Flask principale
â”œâ”€â”€ data.jsonl            # DonnÃ©es textuelles sources
â”œâ”€â”€ .env                  # Stockage des clÃ©s API
â””â”€â”€ requirements.txt      # DÃ©pendances
```

---

## ğŸ“Œ Notes

* Requiert une `GROQ_API_KEY` valide.
* VÃ©rifiez que `data.jsonl` existe et contient au moins une entrÃ©e JSON avec un champ `"text"`.

---

## ğŸ’¡ Cas d'Usage

**Ã‰ducation** : Les enseignants peuvent automatiser la correction de rÃ©ponses, gÃ©nÃ©rer des retours et garantir l'Ã©quitÃ© grÃ¢ce aux LLMs.
